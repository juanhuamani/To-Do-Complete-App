# ğŸ”¥ Estresar CPU Directamente con kubectl

## ğŸ¯ Comando Directo (MÃ¡s Simple)

### OpciÃ³n 1: Comando Ãšnico (Recomendado)

```bash
# Crear un pod temporal que consuma CPU durante 3 minutos
kubectl run stress-cpu \
  -n todo \
  --image=polinux/stress:latest \
  --restart=Never \
  -- stress --cpu 4 --timeout 180s
```

**ExplicaciÃ³n:**
- `stress --cpu 4`: Consume 4 cores de CPU
- `--timeout 180s`: Ejecuta por 180 segundos (3 minutos)
- `--restart=Never`: No reinicia el pod cuando termine

### OpciÃ³n 2: MÃºltiples Pods (MÃ¡s Carga)

```bash
# Crear mÃºltiples pods de stress para generar mÃ¡s carga
for i in {1..6}; do
  kubectl run stress-cpu-${i} \
    -n todo \
    --image=polinux/stress:latest \
    --restart=Never \
    -- stress --cpu 2 --timeout 180s &
done
```

### OpciÃ³n 3: Usar Script AutomÃ¡tico

```bash
# Ejecutar script automÃ¡tico
bash scripts/stress-cpu-direct.sh
```

**ConfiguraciÃ³n por defecto:**
- DuraciÃ³n: 180 segundos (3 minutos)
- CPU Load: 80%
- Crea 2x pods de stress por cada pod del backend

---

## ğŸ“Š Monitorear Durante la Prueba

### Terminal 1: Monitorear HPA
```bash
watch -n 2 'kubectl get hpa -n todo && echo "" && kubectl get pods -n todo | grep backend'
```

### Terminal 2: Monitorear CPU
```bash
watch -n 5 'kubectl top pods -n todo && echo "" && kubectl top nodes'
```

### Terminal 3: Monitorear Nodos
```bash
watch -n 5 'kubectl get nodes && echo "" && kubectl get pods -n todo -o wide'
```

---

## ğŸ§¹ Limpiar Pods de Stress

### Limpiar todos los pods de stress:
```bash
# Eliminar todos los pods de stress
kubectl delete pod -n todo -l run=stress-cpu

# O eliminar por nombre
kubectl delete pod -n todo stress-cpu-{1..10}

# O eliminar todos los pods temporales
kubectl get pods -n todo | grep stress-cpu | awk '{print $1}' | xargs kubectl delete pod -n todo
```

---

## âš™ï¸ Personalizar la Carga

### Aumentar CPU por pod:
```bash
kubectl run stress-cpu \
  -n todo \
  --image=polinux/stress:latest \
  --restart=Never \
  -- stress --cpu 8 --timeout 180s  # 8 cores en lugar de 4
```

### Aumentar duraciÃ³n:
```bash
kubectl run stress-cpu \
  -n todo \
  --image=polinux/stress:latest \
  --restart=Never \
  -- stress --cpu 4 --timeout 300s  # 5 minutos en lugar de 3
```

### Crear mÃ¡s pods:
```bash
# Crear 10 pods de stress
for i in {1..10}; do
  kubectl run stress-cpu-${i} \
    -n todo \
    --image=polinux/stress:latest \
    --restart=Never \
    -- stress --cpu 2 --timeout 180s &
done
```

---

## âœ… Verificar que Funciona

### Verificar que los pods de stress estÃ¡n corriendo:
```bash
kubectl get pods -n todo | grep stress-cpu
```

### Verificar que estÃ¡n consumiendo CPU:
```bash
kubectl top pods -n todo | grep stress-cpu
```

### Verificar que el HPA estÃ¡ escalando:
```bash
kubectl get hpa -n todo -w
```

---

## ğŸ¯ Resultado Esperado

1. **HPA escalarÃ¡ pods:**
   - De 3 a 5-8 pods cuando CPU > 50%
   - Tiempo: 30-60 segundos

2. **Cluster Autoscaler escalarÃ¡ nodos:**
   - De 2 a 3 nodos cuando pods no caben
   - Tiempo: 2-5 minutos

---

## ğŸ“ Notas

- Los pods de stress se eliminan automÃ¡ticamente cuando terminan
- Si usas `--restart=Never`, el pod no se reiniciarÃ¡
- El comando `stress` consume CPU real, asÃ­ que el HPA deberÃ­a detectarlo
- Puedes ajustar `--cpu` segÃºn el nÃºmero de cores disponibles

---

Â¡Con esto puedes estresar directamente sin modificar el backend! ğŸ”¥

